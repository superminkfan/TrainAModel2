[
  {
    "question": "How do extra nodes in network topology affect overall system performance and reliability?",
    "answer": "Возможные проблемы:\n\n- В топологии есть узлы, которых там быть не должно.\n- Запущен новый кластер, в котором версия топологии (`topVer` в log-файле) отличается от `1`.\nПри конфигурировании узла/узлов для Discovery SPI мог использоваться поисковый механизм Multicast. Пример такой конфигурации:\n\n:::{code-block} xml\n:caption: XML\n<property name=\"ipFinder\">\n                <bean class=\"org.apache.ignite.spi.discovery.tcp.ipfinder.multicast.TcpDiscoveryMulticastIpFinder\">\n                    <property name=\"multicastGroup\" value=\"xxx.xx.xx.xxx\"/>\n                </bean>\n            </property>\n:::\n\nЧтобы проверить количество узлов в топологии, используйте один из способов:\n\n- Heartbeat-сообщение в log-файле `ignite.log`, в котором записывается количество узлов (`hosts`). Пример heartbeat-сообщения:\n   ```bash\n   Cluster [hosts=6, CPUs=9, servers=1, clients=5, topVer=10, minorTopVer=0]\n   ```\n- Команда `--baseline` с помощью консоли `control.sh`. Команда вернет `consistency id` узлов топологии, по которым можно обнаружить лишний узел.\nНастройте класс `TcpDiscoveryVmIpFinder` в конфигурационном файле DataGrid. `TcpDiscoveryVmIpFinder` — статический IP Finder, в его конфигурации указывается набор хостов и портов, которые проверяются при поиске узлов данного кластера.\n\n:::{code-block} xml\n:caption: XML\n<bean class=\"org.apache.ignite.spi.discovery.tcp.ipfinder.vm.TcpDiscoveryVmIpFinder\">\n    <property name=\"addresses\">\n        <list>\n            <value>xxx.x.x.x:47500..47509</value>\n        </list>\n    </property>\n</bean>\n:::"
  },
  {
    "question": "What are the potential impacts on network performance and connectivity when there is a prolonged delay in launching the first node within a network topology?",
    "answer": "Запуск первого узла занимает значительное время, при этом последующие узлы запускаются гораздо быстрее.\nБольшое количество адресов и портов в конфигурации Discovery SPI.\n\nDataGrid сканирует все заданные в конфигурации порты. При включенной защите от сканирования портов может не приходить сообщение `Connection refused`. В этом случае проверка порта будет занимать все время, которое задано в значении тайм-аута `IgniteConfiguration.failureDetectionTimeout` (по умолчанию 10 секунд).\n\nНапример, если в конфигурации 3 адреса и 10 портов на каждый из них, время запуска займет 5 минут (3 адреса \\* 10 портов \\* 10 секунд).\n\n:::{code-block} xml\n:caption: XML\n<bean class=\"org.apache.ignite.spi.discovery.tcp.ipfinder.vm.TcpDiscoveryVmIpFinder\">\n    <property name=\"addresses\">\n        <list>\n            <value>ignite1.local.net:47500..47509</value>\n            <value>ignite2.local.net:47500..47509</value>\n            <value>ignite3.local.net:47500..47509</value>\n        </list>\n    </property>\n</bean>\n:::\nЧтобы решить проблему:\n\n1. Не прописывайте лишние порты и адреса. Указывайте только те, которые используются на самом деле.\n2. Во внутренней сети отключите защиту от сканирования портов.\n3. Снизьте значение `failureDetectionTimeout`, чтобы процесс сканирования проходил быстрее."
  },
  {
    "question": "What are some of the common problems encountered when implementing and using IPv6 in network infrastructures? \n\nThis question encourages an exploration into various issues such as compatibility with existing IPv4 systems, configuration challenges, security concerns, and any potential performance or deployment hurdles that organizations might face during the transition to IPv6.?",
    "answer": "Возможные проблемы:\n\n- Различные сетевые ошибки, которые связаны с невозможностью доставить сообщения и передать данные.\n- Сообщения в log-файле вида:\n   ```bash\n   Failed to connect to address\n\n   Node SEGMENTED\n\n   Failed to send message to remote node\n   ```\nПо умолчанию решения DataGrid тестируются с использованием четвертой версии интернет-протокола (IPv4). При передаче данных с использованием шестой версии (IPv6) могут возникать ошибки, которые описаны выше.\n\nПричина возникновения таких ошибок — смешение окружений IPv4 и IPv6 при переходе с четвертой версии интернет-протокола на шестую.\nДля решения конфликта между версиями установите значение `true` для параметра `-Djava.net.preferIPv4Stack` в конфигурационном файле `Ignite-SE-15.0.0/config/jvm.opts`."
  },
  {
    "question": "What are the key considerations for effectively managing a website during maintenance mode to minimize user impact and ensure a smooth transition back to full operation?",
    "answer": "Возможные проблемы:\n\n- Узел не входит в топологию.\n- В log-файле во время загрузки вместо обычной шапки вида:\n   ```bash\n   >>> Ignite ver. 2.12.0-p7#YYYYMMDD-sha1:00000xxxx\n   >>> OS name: Linux 3.10.0-1160.59.1.el7.x86_64 amd64\n   >>> CPU(s): 16\n   >>> Heap: 15.0GB\n   >>> VM name: 1532437@tvldd-pprb00615\n   >>> Local node[ID=1A60DC51-1655-4527-96B6-2D1D27E033F8, order=2, clientMode=false]\n   >>> Local node addresses:[hostname, /xxx.x.x.x]\n   >>> Local ports: TCP:8080 TCP:10800 TCP:11211 TCP:47100 TCP:4750\n   ```\n\n   появляется шапка вида:\n\n   ```bash\n   >>> Ignite ver. 2.12.0-p7#YYYYMMDD-sha1:00000xxxx\n   >>> --------------------------------------------------------------------------\n   >>> OS name: Linux 3.10.0-1160.59.1.el7.x86_64 amd64\n   >>> CPU(s): -1\n   >>> Heap: 0.1GB\n   >>> VM name: 1963884@tvldd-pprb00614\n   >>> Local node [ID=6D7810F8-C65A-42A8-AA78-35D4FDA29BD6, order=1, clientMode=false]\n   >>> Local node addresses: [localhost/xxx.x.x.x]\n   >>> Local ports: TCP:8080 TCP:10800 TCP:11211 TCP:47100\n   ```\n\n   Также в log-файле появляется сообщение об ошибке:\n   ```bash\n   [INFO ][main][org.apache.ignite.internal.IgniteKernal] Node is being started in maintenance mode. Starting IsolatedDiscoverySpi instead of configured discovery SPI.\n   ```\nУзел загрузился в режиме Maintenance Mode — он предназначен для обслуживания узлов кластера с включенной персистентностью. Когда узел находится в этом режиме, на нем можно выполнять разные команды через скрипты и подключаться через JMX, но в топологию он не входит.\n\nВозможные причины перехода в режим Maintenance:\n\n- очистка поврежденных файлов PDS (Persistence Data Store);\n- дефрагментация Native Persistence.\n\nКонкретная причина указывается в сообщении log-файла:\n\n```bash\n[INFO ][main][org.apache.ignite.internal.maintenance.MaintenanceProcessor] Node requires maintenance, non-empty set of maintenance tasks is found: [*corrupted-cache-data-files-task*]\n```\n##### Очистка поврежденных файлов PDS\n\nВозможный сценарий:\n\n1. Узел падает в процессе checkpointing, пока WAL-архив отключен для одного или нескольких кешей.\n2. При следующем перезапуске узел обнаруживает, что файлы данных кеша могут быть повреждены, поэтому создает соответствующий Maintenance Task и отключается.\n3. Во время следующего перезапуска узел переходит в Maintenance Mode и ожидает от пользователя решения проблемы.\n\nВ управляемых средах (например, Kubernetes) это означает, что узел не перезапустится автоматически и пользователь сможет найти возможные поврежденные файлы и удалить их. Когда файлы удаляются вручную, пользователь также удаляет Maintenance Task из регистра и перезапускает узел. В результате узел запускается в нормальном режиме и присоединяется к кластеру.\n\n##### Дефрагментация Native Persistence\n\nВозможный сценарий:\n\n1. Пользователь с помощью скрипта `control.sh` или запросов других API создает Maintenance Task для дефрагментации Native Persistence на узле или определенных кешах.\n2. Пользователь перезапускает узел. Он входит в режим Maintenance, находит Maintenance Task по дефрагментации и начинает выполнение задачи.\n3. Когда дефрагментация завершается, Maintenance Task автоматически удаляется. При следующем перезапуске узел присоединяется к топологии."
  },
  {
    "question": "What are some common issues encountered when implementing marshals or serialization in software development, and how can they be effectively addressed?",
    "answer": "Сообщения в log-файле одного из видов:\n\n- ```bash\n  Some classes in query configuration cannot be written in binary format...\n  ```\n\n- ```bash\n  Class FooBar cannot be serialized using BinaryMarshaller\n  ```\nПри взаимодействии продуктового кода с кодом DataGrid происходит сериализация. Это процесс, при котором продуктовый код преобразуется в формат, пригодный для хранения или передачи. Подробнее о сериализации написано в разделе [«Термины и определения»](../../glossary/md/glossary.md).\n\nПри записи данных в память для дальнейшего использования DataGrid сериализует объекты с помощью трех механизмов:\n\n- `JDK Marshaller` — обычная Java-сериализация.\n- `Optimized Marshaller` — оптимизированная Java-сериализация, при которой используются те же механизмы, что и в случае `JDK Marshaller`. Этот механизм обеспечивает обратную совместимость с Ignite 1.9.\n- `Binary Marshaller` — сериализация, которая создана специально для Apache Ignite и используется в DataGrid по умолчанию. Это наиболее быстрый механизм, который позволяет избегать дополнительной сериализации и десериализации, а также работать с объектом напрямую в бинарном формате.\n\nПроблемы с сериализацией классов могут возникать при использовании пользовательской реализации методов `readObject()` и `writeObject()` с помощью интерфейса `Externalizable`. В этом случае невозможна сериализация с помощью механизма `Binary Marshaller` по умолчанию, так как он сериализует объекты с помощью обычной записи полей и простых методов. В случае пользовательской сериализации DataGrid переключится на механизм `Optimized Marshaller` — это может привести к падению производительности."
  },
  {
    "question": "How do time-auto records enhance synchronization and data integrity across client nodes in distributed systems?",
    "answer": "Возможные проблемы:\n\n- При подключении клиентских узлов и попытке записи на них `TcpCommunicationSpi` перестает работать по тайм-аутам:\n   ```bash\n   YYYY-MM-DD 17:23:40:275 [WARN ] [org.apache.ignite.spi.communication.tcp.TcpCommunicationSpi] [grid-timeout-worker-#118%DPL_GRID%DplGridNodeName%] - Handshake timed out (will stop attempts to perform the handshake) [node=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx, connTimeoutStrategy=ExponentialBackoffTimeoutStrategy [maxTimeout=600000, totalTimeout=30000, startNanos=xxxxxxxxxxxxxxxx, currTimeout=600000], err=Operation timed out [timeoutStrategy= ExponentialBackoffTimeoutStrategy [maxTimeout=600000, totalTimeout=30000, startNanos=xxxxxxxxxxxxxxxx, currTimeout=600000]], addr=/xxx.xxx.xxx.x:xxxxx, failureDetectionTimeoutEnabled=true, timeout=0]\n   ```\n- В log-файлах сервера при наличии данной проблемы отображается много попыток входящих соединений:\n   ```bash\n   YYYY-MM-DD 17:24:29.141 [INFO ][grid-nio-worker-tcp-comm-10-#129%TcpCommunicationSpi%][org.apache.ignite.spi.communication.tcp.TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/xxx.xxx.xxx.x:xxxxx, rmtAddr=/xxx.xxx.xxx.x:42776]\n   ```\n\nВ целях диагностики обратите внимание на:\n\n- IP-адрес, по которому происходит `time out handshake`;\n- IP-адрес, с которым запущен кластер.\nПроблема появляется, когда:\n\n- в операционной системе настроено несколько сетевых интерфейсов;\n- `TcpCommunicationSpi` запускается в интерфейсе, отличающемся от того, на котором работает кластер:\n   ```bash\n   YYYY-MM-DD 00:00:10.362 [INFO ][grid-timeout-worker-#118][org.apache.ignite.internal.IgniteKernal]\n   Metrics for local node (to disable set 'metricsLogFrequency' to 0)\n       ^-- Node [id=7eace3d5, uptime=1 day, 05:29:46.136]\n       ^-- Cluster [hosts=32, CPUs=1792, servers=32, clients=9, topVer=53, minorTopVer=0]\n       ^-- Network [addrs=[xx.xxx.xxx.xxx, xxx.x.x.x, xxx.xxx.xxx.x], discoPort=47500, commPort=47100]\n       ^-- CPU [CPUs=56, curLoad=0.03%, avgLoad=0.05%, GC=0%]\n       ^-- Heap [used=10953MB, free=65.49%, comm=31744MB]\n       ^-- Off-heap memory [used=132MB, free=99.98%, allocated=592071MB]\n       ^-- Page memory [pages=33435]\n       ^--   sysMemPlc region [type=internal, persistence=true, lazyAlloc=false,\n         ...  initCfg=40MB, maxCfg=100MB, usedRam=0MB, freeRam=99.99%, allocRam=99MB, allocTotal=0MB]\n       ^--   default region [type=default, persistence=true, lazyAlloc=true,\n         ...  initCfg=256MB, maxCfg=591872MB, usedRam=130MB, freeRam=99.98%, allocRam=591871MB, allocTotal=129MB]\n       ^--   metastoreMemPlc region [type=internal, persistence=true, lazyAlloc=false,\n         ...  initCfg=40MB, maxCfg=100MB, usedRam=2MB, freeRam=97.99%, allocRam=0MB, allocTotal=2MB]\n       ^--   TxLog region [type=internal, persistence=true, lazyAlloc=false,\n         ...  initCfg=40MB, maxCfg=100MB, usedRam=0MB, freeRam=100%, allocRam=99MB, allocTotal=0MB]\n       ^--   volatileDsMemPlc region [type=user, persistence=false, lazyAlloc=true,\n         ...  initCfg=40MB, maxCfg=100MB, usedRam=0MB, freeRam=100%, allocRam=0MB]\n       ^-- Ignite persistence [used=131MB]\n       ^-- Outbound messages queue [size=0]\n       ^-- Public thread pool [active=0, idle=0, qSize=0]\n       ^-- System thread pool [active=0, idle=7, qSize=0]\n   ```\nУкажите в bean `TcpCommunicationSpi` свойство с локальным IP-адресом, на котором запущен кластер (`TcpDiscoveryVmIpFinder`).\n\n:::{code-block} xml\n:caption: XML\n<property name=\"localAddress\" value=\"x.x.x.x\"/>\n:::"
  },
  {
    "question": "What are the key strategies for optimizing long transactions in low-latency trading systems to enhance performance and minimize execution delays?",
    "answer": "Возможные проблемы:\n\n- Сработала метрика `LRT Found long running transaction NEW` в Grafana.\n- В log-файле `ignite.log` есть сообщения вида:\n   ```bash\n   [YYYY-MM-DD 11:41:53,530][WARN ][sys-#206%client%][root] First 10 long running transactions [total=10]\n   [YYYY-MM-DD 11:41:53,530][WARN ][sys-#206%client%][root] >>> Transaction [startTime=11:41:52.961, curTime=11:41:53.518, systemTime=0, userTime=557, tx=GridNearTxLocal [mappings=IgniteTxMappingsImpl [], nearLocallyMapped=false, colocatedLocallyMapped=false, needCheckBackup=null, hasRemoteLocks=false, trackTimeout=false, systemTime=0, systemStartTime=0, prepareStartTime=0, prepareTime=0, commitOrRollbackStartTime=0, commitOrRollbackTime=0, lb=null, mvccOp=null, qryId=-1, crdVer=0, thread=async-tx-with-delay-#240%testscope%, mappings=IgniteTxMappingsImpl [], super=GridDhtTxLocalAdapter [nearOnOriginatingNode=false, span=o.a.i.i.processors.tracing.NoopSpan@60d3a365, nearNodes=KeySetView [], dhtNodes=KeySetView [], explicitLock=false, super=IgniteTxLocalAdapter [completedBase=null, sndTransformedVals=false, depEnabled=false, txState=IgniteTxStateImpl [activeCacheIds=[], recovery=null, mvccEnabled=null, mvccCachingCacheIds=[], txMap=EmptySet []], super=IgniteTxAdapter [xidVer=GridCacheVersion [topVer=244989714, order=1633509712519, nodeOrder=3], writeVer=null, implicit=false, loc=true, threadId=264, startTime=1633509712961, nodeId=390487f0-99c2-4890-992c-c9c3ac93d505, isolation=REPEATABLE_READ, concurrency=PESSIMISTIC, timeout=0, sysInvalidate=false, sys=false, plc=2, commitVer=null, finalizing=NONE, invalidParts=null, state=ACTIVE, timedOut=false, topVer=AffinityTopologyVersion [topVer=-1, minorTopVer=0], mvccSnapshot=null, skipCompletedVers=false, parentTx=null, duration=557ms, onePhaseCommit=false], size=0]]]]\n   ...\n   ```\nНекоторые события кластера запускают процесс обмена данными между узлами и их ребалансировку, чтобы обеспечить равномерное распределение данных по всему кластеру. Примеры таких событий — изменение топологии при подключении нового или отключении существующего узла, создание новых кешей или SQL-таблиц.\n\nПри возникновении подобных событий в DataGrid может увеличиться порог времени проведения транзакций (по умолчанию 60 секунд). Проблема часто связана с появлением LRT — длительных транзакций, которые долго выполняются в кластере. Незавершенные транзакции препятствуют обмену данными, так как они блокируют операции кластера, например процесс подключения нового узла.\n\nДля решения проблемы проанализируйте содержимое log-файла, в котором присутствуют сообщения вида `Found long running transaction NEW`. Возможные причины увеличения длительности транзакции:\n\n- Длительная работа прикладного кода. Об этой проблеме свидетельствует наличие транзакции в активном статусе (`status=active`).\n- Неисправное состояние кластера, при котором транзакции перестали выполняться, например при отказе дисков.\n\nПри первом сообщении о появлении LRT в log-файле серверного узла выведется дамп потока, который запустил LRT на узле-координаторе транзакции. Часто этот узел является клиентским, то есть дамп потока транзакции также будет получен с клиентского узла. Дамп показывает тип выполняемой операции (бизнес-операция или взаимодействие с DataGrid). Признаки, которые присутствуют в дампах транзакций и свидетельствуют о наличии задержек:\n\n- атрибуты `TransactionProxyImpl.commit`, `TransactionProxyImpl.rollback` и `TransactionProxyImpl.prepare` свидетельствуют о задержках работы сети или GC-задержках (очистка мусора);\n- бизнес-коды, кеш-операции и другие параметры промежуточного состояния свидетельствуют о задержках в работе прикладного кода или о низких тайм-аутах транзакций.\n\nПример записи в log-файле:\n\n```bash\nYYYY-MM-DD 05:31:08.093 [WARN ][sys-#112111][org.apache.ignite.internal.diagnostic] Dumping the near node thread that started transaction [xidVer=GridCacheVersion [topVer=267985566, order=1658822904791, nodeOrder=29, dataCenterId=0], nodeId=b1076c6d-e26d-44ff-bd30-af41845a42ed]\nStack trace of the transaction owner thread:\nThread [name=\"se-53\", id=1353, state=WAITING, blockCnt=1, waitCnt=1788]\nLock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@a19d495, ownerName=null, ownerId=-1]\nat sun.misc.Unsafe.park(Native Method)\nat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\nat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\nat java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)\nat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\nat java.lang.Thread.run(Thread.java:748)\n```\n\nLRT-транзакции часто возникают в результате следующих причин:\n\n- повышенная загрузка узлов кластера;\n- наличие сетевых проблем, которые приводят к деградации вычислений;\n- системные проблемы — длительные GC-паузы на узлах, неоптимальный код, падение узлов кластера.\n\nЧтобы настроить время срабатывания для вывода сообщений о наличии LTR-транзакций, используйте JVM-опцию `IGNITE_LONG_OPERATIONS_DUMP_TIMEOUT`. По умолчанию время вывода сообщений — 1 секунда.\n\nЧтобы установить максимальное время для длительных транзакций, используйте метод `TransactionConfiguration.setTxTimeoutOnPartitionMapExchange(...)`. Когда сработал тайм-аут, происходит откат всех незавершенных транзакций, после этого процесс обмена данными в кластере продолжается.\n\nПример XML-файла для конфигурации времени тайм-аута:\n\n:::{code-block} xml\n:caption: XML\n<bean class=\"org.apache.ignite.configuration.IgniteConfiguration\">\n\n    <property name=\"transactionConfiguration\">\n        <bean class=\"org.apache.ignite.configuration.TransactionConfiguration\">\n            <!-- Установите тайм-аут на 20 секунд .-->\n            <property name=\"TxTimeoutOnPartitionMapExchange\" value=\"20000\"/>\n        </bean>\n    </property>\n\n</bean>\n:::\n\nЧек-лист вопросов для анализа LRT-транзакций:\n\n- В чем причина возникновения LRT?\n- Каким способом можно восстановить LRT — автоматически или вручную?\n- Что нужно сделать, чтобы снизить вероятность повторения сбоя в будущем?\n- Как LRT-транзакция повлияла на данные и дальнейшую работу?"
  },
  {
    "question": "What are the potential causes and implications of experiencing prolonged periods of post-exercise malaise (PME) after intense physical activity?",
    "answer": "PME занимает продолжительное время.\n\nPME (Partition Map Exchange) — процесс обмена информацией о партициях между узлами кластера. Его цель — установить актуальное состояние партиций для всех узлов кластера.\nПродолжительность PME зависит от количества партиций и длительности транзакций, которые должны завершиться перед началом процесса обмена. Чем меньше длительность PME, тем лучше.\n\nК симптомам относится срабатывание метрик по LRT, например `Found Long Running Transactions NEW`.\n\nСимптомы вызваны следующими проблемами:\n\n- создание транзакций без тайм-аутов или с большими тайм-аутами;\n- наличие дефектов.\n\nЕсть вероятность, что транзакция никогда не будет завершена. Например, если пользователь запустил `PESSIMISTIC`-транзакции и выполнил  `cache put`, который вызывает блокировку и настройку версии топологии транзакций. Для этого случая вводится `timeout` транзакции на PME. Если транзакция не может завершиться в рамках указанного`timeout`, она принудительно отменяется перед началом PME.\nУстановите время в `setTxTimeoutOnPartitionMapExchange(long txTimeoutOnPartitionMapExchange)`. Если на момент начала PME транзакция не завершится, начнется отсчет этого тайм-аута. Когда он истечет, произойдет откат транзакции.\n\nЕсли тайм-ауты для транзакций не настроили должным образом, есть большая вероятность возникновения «повисших» транзакций. Их придется искать вручную и останавливать с помощью скрипта `control.sh`."
  },
  {
    "question": "What are the potential causes of damage to H2 database indexes, and how can such issues be effectively diagnosed and resolved?",
    "answer": "Узлы завершают работу с ошибками вида `Critical system error detected. Will be handled accordingly to configured handler`. Поломка индексов выявляется в результате выполнения команды `control.sh` `--cache validate_indexes <optional arguments>`.\n\nВ log-файле появятся сообщения об ошибке. О поломке индексов свидетельствует сообщение `CorruptedTreeException: B+Tree is corrupted`:\n\n```bash\nYYYY-MM-DD 17:33:43.466 [ERROR][sys-stripe-9-#10][] Critical system error detected. Will be handled accordingly to configured handler [hnd=StopNodeOrHaltFailureHandler [tryStop=false, timeout=0, super=AbstractFailureHandler [ignoredFailureTy\npes=UnmodifiableSet [SYSTEM_WORKER_BLOCKED, SYSTEM_CRITICAL_OPERATION_TIMEOUT]]], failureCtx=FailureContext [type=CRITICAL_ERROR, err=class o.a.i.i.processors.cache.persistence.tree.CorruptedTreeException: B+Tree is corrupted [pages(groupId,\npageId)=[IgniteBiTuple [val1=544320549, val2=844420635174666]], cacheId=-227153373, cacheName=APPLY_ERROR_V1, indexName=_key_PK, msg=Runtime failure on row: Row@4118366a[ key: BinaryObject [idHash=974233043, hash=1604362618], val: Data hidd\nen due to IGNITE_TO_STRING_INCLUDE_SENSITIVE flag. ][ data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden ]]]]\norg.apache.ignite.internal.processors.cache.persistence.tree.CorruptedTreeException: B+Tree is corrupted [pages(groupId, pageId)=[IgniteBiTuple [val1=544320549, val2=844420635174666]], cacheId=-227153373, cacheName=APPLY_ERROR_V1, indexName=\n_key_PK, msg=Runtime failure on row: Row@4118366a[ key: BinaryObject [idHash=974233043, hash=1604362618], val: Data hidden due to IGNITE_TO_STRING_INCLUDE_SENSITIVE flag. ][ data hidden, data hidden, data hidden, data hidden, data hidden, da\nta hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden, data hidden ]]\n```\nПерестройте индексы:\n\n1. Остановите проблемные узлы.\n2. Удалите проблемный файл `index.bin`.\n3. Запустите узлы.\n4. Выполните процесс перестройки всех индексов с помощью команды `control.sh` `z--cache indexes_force_rebuild --node-ids nodeId1,...nodeIdN|--all-nodes --cache-names cacheName1,...cacheNameN|--group-names groupName1,...groupNameN`.\n5. Дождитесь завершения процесса перестройки индексов."
  },
  {
    "question": "What are the primary causes of uneven loading in distributed systems, and how can they be effectively mitigated to ensure balanced performance across all nodes?",
    "answer": "Неравномерное распределение данных по узлам кластера и неравномерная нагрузка на них.\n\nНекорректное распределение данных и ошибки кода могут приводить к скоплению запросов на одном узле. Из-за этого возникает неравномерная загрузка на остальные узлы:\n\n- на уровне аппаратных и/или физических ресурсов, к которым относятся CPU, SSD, RAM, LAN, аппаратные ресурсы узлов кластера;\n- на уровне неаппаратных ресурсов, к которым относятся системные потоки кластера (thread pools), все виды памяти в операционной системе, партиции и так далее.\n\nКаждый вид ресурсов может утилизироваться преимущественно на одном из узлов. Из-за этого кластер не сможет отрабатывать запросы со скоростью, которая требуется по SLA, или развалится.\n\nМониторинг симптомов возможен с помощью сбора фактуры `ignite.log`, метрик DataGrid и операционной системы.\nВозможные причины проблемы:\n\n- некорректная конфигурация, например указан только один IP-адрес;\n- ошибки в коде, из-за которых данные и запросы направляются на один узел.\nДля решения проблемы установите причину концентрации данных.\n\nЕсли причина в некорректной конфигурации, настройте ее. Если проблема в коде, найдите ошибки и решите проблему с ключами, разнесением данных по узлам и партициям."
  },
  {
    "question": "What are the common causes of slow disk performance in computers, and how can they be effectively addressed?",
    "answer": "Возможные причины проблемы:\n\n- увеличение продолжительности процесса Checkpointing;\n- checkpoints spikes на графике;\n- кластер «тормозит».\nВероятная причина проблемы — несбалансированность пропускной способности памяти и диска. В целях диагностики проверьте метрику, которая показывает количество сбрасываемых страниц (`LastCheckpointTotalPagesNumber`). Если она коррелирует с увеличением длительности checkpointing, с большой вероятностью проблемы нет, а время увеличилось за счет роста нагрузки на диск.\n\nЕсли метрика не коррелирует с длительностью checkpointing, проанализируйте содержимое `ignite.log`, `dmesg` и  `messages`— возможно, диск утилизирован или возникла проблема на уровне операционной системы или железа. Для решения проблемы передайте службе поддержки DataGrid содержимое файлов `ignite`, `dmesg` и `messages`.\nРешение зависит от результатов, которые будут получены после изучения log-файла на наличие сообщений уровня `ERROR` и `WARN`."
  },
  {
    "question": "How can mutual blocking, also known as deadlock, be prevented in operating systems?",
    "answer": "Возможные проблемы:\n\n- Замедление бизнес-операций.\n- Завершение транзакций сообщениями вида:\n  - на серверных узлах:\n    ```bash\n     [ERROR][grid-timeout-worker-#118][org.apache.ignite.internal.processors.cache.distributed.dht.colocated.GridDhtColocatedCache] <tw.transactions> Failed to acquire lock for request: GridNearLockRequest [topVer=AffinityTopologyVersion [topVer=418, minorTopVer=0], miniId=1, dhtVers=GridCacheVersion[] [null], subjId=088f0b3b-8b8c-4d41-ab0c-73cd0d5af2f8, taskNameHash=0, createTtl=-1, accessTtl=-1, flags=5, txLbl=null, filter=null, super=GridDistributedLockRequest [nodeId=088f0b3b-8b8c-4d41-ab0c-73cd0d5af2f8, nearXidVer=GridCacheVersion [topVer=245981357, order=1637825079145, nodeOrder=400], threadId=8689, futId=334a5c5cc71-0864976c-edcc-4d9e-bb9a-92b2b91a2bd2, timeout=30000, isInTx=true, isInvalidate=false, isRead=true, isolation=REPEATABLE_READ, retVals=[true], txSize=0, flags=2, keysCnt=1, super=GridDistributedBaseMessage [ver=GridCacheVersion [topVer=245981357, order=1637825079145, nodeOrder=400], committedVers=null, rolledbackVers=null, cnt=0, super=GridCacheIdMessage [cacheId=92902112, super=GridCacheMessage [msgId=155993, depInfo=null, lastAffChangedTopVer=AffinityTopologyVersion [topVer=24, minorTopVer=71], err=null, skipPrepare=false]]]]]\n     org.apache.ignite.internal.transactions.IgniteTxTimeoutCheckedException: Failed to acquire lock within provided timeout for transaction [timeout=30000, tx=GridDhtTxLocal[xid=8776bf55d71-00000000-0ea9-60ad-0000-000000000004, xidVersion=GridCacheVersion [topVer=245981357, order=1637825079160, nodeOrder=4], nearXidVersion=GridCacheVersion [topVer=245981357, order=1637825079145, nodeOrder=400], concurrency=PESSIMISTIC, isolation=REPEATABLE_READ, state=MARKED_ROLLBACK, invalidate=false, rollbackOnly=true, nodeId=63a1650c-7291-44be-a5b7-3be796c4ad6f, timeout=30000, startTime=1635424056538, duration=30007]]\n     at org.apache.ignite.internal.processors.cache.transactions.IgniteTxLocalAdapter$PostLockClosure1.apply(IgniteTxLocalAdapter.java:1798) ~[ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.processors.cache.transactions.IgniteTxLocalAdapter$PostLockClosure1.apply(IgniteTxLocalAdapter.java:1746) ~[ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridEmbeddedFuture$2.applyx(GridEmbeddedFuture.java:86) ~[ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridEmbeddedFuture$AsyncListener1.apply(GridEmbeddedFuture.java:292) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridEmbeddedFuture$AsyncListener1.apply(GridEmbeddedFuture.java:285) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridFutureAdapter.notifyListener(GridFutureAdapter.java:399) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridFutureAdapter.unblock(GridFutureAdapter.java:347) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridFutureAdapter.unblockAll(GridFutureAdapter.java:335) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridFutureAdapter.onDone(GridFutureAdapter.java:511) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.processors.cache.GridCacheCompoundIdentityFuture.onDone(GridCacheCompoundIdentityFuture.java:56) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.future.GridFutureAdapter.onDone(GridFutureAdapter.java:490) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.processors.cache.distributed.dht.GridDhtLockFuture.onComplete(GridDhtLockFuture.java:802) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.processors.cache.distributed.dht.GridDhtLockFuture.access$900(GridDhtLockFuture.java:93) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.processors.cache.distributed.dht.GridDhtLockFuture$LockTimeoutObject.onTimeout(GridDhtLockFuture.java:1202) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.processors.timeout.GridTimeoutProcessor$TimeoutWorker.body(GridTimeoutProcessor.java:234) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at org.apache.ignite.internal.util.worker.GridWorker.run(GridWorker.java:120) [ignite-core-2.10.0-p1.jar:2.10.0-p1]\n     at java.lang.Thread.run(Thread.java:748) [?:1.8.0_301]\n     ```\n   - на инициаторе транзакции:\n     ```bash\n     Caused by: javax.cache.CacheException: class org.apache.ignite.transactions.TransactionTimeoutException: Failed to acquire lock within provided timeout for transaction [timeout=30000, tx=GridNearTxLocal[xid=f3c4b265d71-00000000-0ea9-60ad-0000-00000000019a, xidVersion=GridCacheVersion [topVer=245981357, order=1637828217919, nodeOrder=410], nearXidVersion=GridCacheVersion [topVer=245981357, order=1637828217919, nodeOrder=410], concurrency=PESSIMISTIC, isolation=REPEATABLE_READ, state=MARKED_ROLLBACK, invalidate=false, rollbackOnly=true, nodeId=68ca22f4-38be-4027-8c81-94b0ea81559e, timeout=30000, startTime=1635430164207, duration=30016, label=null]]\n        at org.apache.ignite.internal.processors.cache.GridCacheUtils.convertToCacheException(GridCacheUtils.java:1263)\n        at org.apache.ignite.internal.processors.cache.IgniteCacheProxyImpl.cacheException(IgniteCacheProxyImpl.java:2083)\n        at org.apache.ignite.internal.processors.cache.IgniteCacheProxyImpl.get(IgniteCacheProxyImpl.java:1110)\n        at org.apache.ignite.internal.processors.cache.GatewayProtectedCacheProxy.get(GatewayProtectedCacheProxy.java:676)\n        at com.sbt.processing.data.ignite.IgniteWriter.writeIdentifiableInternal(IgniteWriter.java:95)\n        at com.sbt.processing.data.ignite.IgniteWriter.appendIdentifiable(IgniteWriter.java:74)\n        ... 17 more\n        Caused by: class org.apache.ignite.transactions.TransactionTimeoutException: Failed to acquire lock within provided timeout for transaction [timeout=30000, tx=GridNearTxLocal[xid=f3c4b265d71-00000000-0ea9-60ad-0000-00000000019a, xidVersion=GridCacheVersion [topVer=245981357, order=1637828217919, nodeOrder=410], nearXidVersion=GridCacheVersion [topVer=245981357, order=1637828217919, nodeOrder=410], concurrency=PESSIMISTIC, isolation=REPEATABLE_READ, state=MARKED_ROLLBACK, invalidate=false, rollbackOnly=true, nodeId=68ca22f4-38be-4027-8c81-94b0ea81559e, timeout=30000, startTime=1635430164207, duration=30016, label=null]]\n        at org.apache.ignite.internal.util.IgniteUtils$13.apply(IgniteUtils.java:987)\n        at org.apache.ignite.internal.util.IgniteUtils$13.apply(IgniteUtils.java:984)\n        ... 23 more\n        Caused by: class org.apache.ignite.transactions.TransactionDeadlockException:\n        Deadlock detected:\n     K1: TX1 holds lock, TX2 waits lock.\n     K2: TX2 holds lock, TX1 waits lock.\n     Transactions:\n     TX1 [txId=GridCacheVersion [topVer=245981357, order=1637828217886, nodeOrder=418], nodeId=1d0a56c0-cc47-4369-b9c5-c5fe1fffe7bf, threadId=1176]\n     TX2 [txId=GridCacheVersion [topVer=245981357, order=1637828217919, nodeOrder=410], nodeId=68ca22f4-38be-4027-8c81-94b0ea81559e, threadId=12957]\n     Keys:\n     K1 [key=d6oDXoRGCvEAAAF8x+CxoMaIDaIpVm6K, cache=tw.transactions_bundle]\n     K2 [key=d6oDXoRGCvEAAAF8x+CxoMaIDaIpVm6K, cache=tw.transactions]\n         at org.apache.ignite.internal.processors.cache.distributed.dht.colocated.GridDhtColocatedLockFuture$LockTimeoutObject$1.apply(GridDhtColocatedLockFuture.java:1539)\n         at org.apache.ignite.internal.processors.cache.distributed.dht.colocated.GridDhtColocatedLockFuture$LockTimeoutObject$1.apply(GridDhtColocatedLockFuture.java:1532)\n         at org.apache.ignite.internal.util.future.GridFutureAdapter.notifyListener(GridFutureAdapter.java:399)\n         at org.apache.ignite.internal.util.future.GridFutureAdapter.unblock(GridFutureAdapter.java:347)\n         at org.apache.ignite.internal.util.future.GridFutureAdapter.unblockAll(GridFutureAdapter.java:335)\n         at org.apache.ignite.internal.util.future.GridFutureAdapter.onDone(GridFutureAdapter.java:511)\n         at org.apache.ignite.internal.util.future.GridFutureAdapter.onDone(GridFutureAdapter.java:490)\n         at org.apache.ignite.internal.processors.cache.transactions.TxDeadlockDetection$TxDeadlockFuture.onDone(TxDeadlockDetection.java:538)\n         at org.apache.ignite.internal.processors.cache.transactions.TxDeadlockDetection$TxDeadlockFuture.onDone(TxDeadlockDetection.java:163)\n         at org.apache.ignite.internal.util.future.GridFutureAdapter.onDone(GridFutureAdapter.java:467)\n         at org.apache.ignite.internal.processors.cache.transactions.TxDeadlockDetection$TxDeadlockFuture.detect(TxDeadlockDetection.java:314)\n         at org.apache.ignite.internal.processors.cache.transactions.TxDeadlockDetection$TxDeadlockFuture.onResult(TxDeadlockDetection.java:514)\n         at org.apache.ignite.internal.processors.cache.transactions.IgniteTxManager$DeadlockDetectionListener.onMessage(IgniteTxManager.java:3593)\n         at org.apache.ignite.internal.managers.communication.GridIoManager.invokeListener(GridIoManager.java:1908)\n         at org.apache.ignite.internal.managers.communication.GridIoManager.processRegularMessage0(GridIoManager.java:1529)\n         at org.apache.ignite.internal.managers.communication.GridIoManager.access$5300(GridIoManager.java:242)\n         at org.apache.ignite.internal.managers.communication.GridIoManager$9.execute(GridIoManager.java:1422)\n         at org.apache.ignite.internal.managers.communication.TraceRunnable.run(TraceRunnable.java:55)\n         at org.apache.ignite.internal.util.StripedExecutor$Stripe.body(StripedExecutor.java:569)\n         at org.apache.ignite.internal.util.worker.GridWorker.run(GridWorker.java:120)\n         ... 1 more\n     ```\nПо сообщению на инициаторе транзакции определите, на каком ключе произошла взаимоблокировка:\n\n```bash\nK1 [key=d6oDXoRGCvEAAAF8x+CxoMaIDaIpVm6K, cache=tw.transactions_bundle]\nK2 [key=d6oDXoRGCvEAAAF8x+CxoMaIDaIpVm6K, cache=tw.transactions]\n```\n\nОбычно данную информацию нужно передать на анализ прикладным разработчикам, чтобы они смогли определить причины возникновения взаимоблокировки в коде. Если добавлен параметр `-DIGNITE_TO_STRING_INCLUDE_SENSITIVE=false`, значение ключей не будет попадать в log-файл и по сообщениям не получится узнать, на каких ключах произошла взаимоблокировка.\n\n```bash\nK1 [key=, cache=tw.transactions_bundle]\nK2 [key=, cache=tw.transactions]\n```\n\nОбнаружение взаимоблокировок — многоэтапная процедура, для которой может понадобиться много итераций в зависимости от количества узлов в кластере, ключей и транзакций, которые участвуют в возможном deadlock.\n\nИнициатор обнаружения взаимоблокировки — узел, на котором транзакция началась, но была прервана с исключением `TransactionTimeOutException`. Этот узел будет исследовать, произошла ли взаимоблокировка: обмениваться запросами/ответами с другими удаленными узлами. Затем он подготовит отчет о взаимоблокировке с помощью `TransactionDeadlockException`. Каждое такое сообщение (запрос/ответ) — одна итерация.\n\nДля предсказуемого времени отката транзакции настройте максимальное количество итераций для процедуры обнаружения взаимоблокировки — `Ignitesystemproperties.ignite_tx_deadlock_detection_max_iters`. Если значение свойства — `0` и меньше, `deadlock detection` будет отключен (по умолчанию 1000). `Ignitesystemproperties.ignite_tx_deadlock_detection_timeout` указывает время ожидания для обнаружения взаимоблокировки (по умолчанию 1 минута).\n\nНастроить другой тайм-аут можно с помощью опции `-DIGNITE_TX_DEADLOCK_DETECTION_TIMEOUT=<new_timeout>`."
  },
  {
    "question": "What are some general troubleshooting steps to take if a node fails to launch? \n\nThis question invites suggestions for actions like verifying configuration settings, checking system requirements, reviewing logs for errors, ensuring network connectivity, or restarting services. It helps guide someone facing issues with launching a node in computing environments such as distributed networks or blockchain systems.?",
    "answer": ""
  },
  {
    "question": "What could be the potential causes and solutions for an error message stating \"Unable to Establish Secure Connection\" when trying to launch a website or application?",
    "answer": "Возможные проблемы:\n\n- Не запускается клиентский узел.\n- В log-файле клиентского узла есть сообщение:\n  ```bash\n  DD.MM.YYYY 15:36:44,654 INFO  [stdout] (ServerService Thread Pool – 105) Caused by: org.apache.ignite.spi.IgniteSpiException: Unable to establish secure connection. Was remote cluster configured with SSL? [rmtAddr=/xx.xxx.xx.xxx:47500, errMsg=\"Received fatal alert: handshake_failure\"]\n  ```\nУбедитесь, что в XML-конфигурации клиентского и серверного узлов установлено одно и то же значение:\n\n:::{code-block} xml\n:caption: XML\n<property name=\"protocols\" value=\"#{systemProperties['https.protocols']}\" />\n:::"
  },
  {
    "question": "What are some common reasons why a server fails to bind to any specified host and port range, and how can these issues be resolved?",
    "answer": "Возможные проблемы:\n\n- Не запускается серверный узел.\n- В log-файле серверного узла есть сообщение:\n  ```bash\n  YYYY-MM-DD 15:35:07.381 [ERROR][main][org.apache.ignite.internal.IgniteKernal] Got exception while starting (will rollback startup routine).\n  org.apache.ignite.IgniteCheckedException: Failed to start processor: GridProcessorAdapter []\n  at org.apache.ignite.internal.IgniteKernal.startProcessor(IgniteKernal.java:1960) ~[ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgniteKernal.start(IgniteKernal.java:1237) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.start0(IgnitionEx.java:2046) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.start(IgnitionEx.java:1698) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx.start0(IgnitionEx.java:1114) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx.startConfigurations(IgnitionEx.java:1032) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:918) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:817) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:687) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:656) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.Ignition.start(Ignition.java:353) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.startup.cmdline.CommandLineStartup.main(CommandLineStartup.java:300) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  Caused by: org.apache.ignite.IgniteCheckedException: Failed to start client connector processor.\n  at org.apache.ignite.internal.processors.odbc.ClientListenerProcessor.start(ClientListenerProcessor.java:215) ~[ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgniteKernal.startProcessor(IgniteKernal.java:1957) ~[ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  ... 11 more\n  Caused by: org.apache.ignite.IgniteCheckedException: Failed to bind to any [host:port] from the range [host=0.0.0.0, portFrom=10800, portTo=10800, lastErr=class org.apache.ignite.IgniteCheckedException: Failed to initialize NIO selector.]\n  at org.apache.ignite.internal.processors.odbc.ClientListenerProcessor.start(ClientListenerProcessor.java:203) ~[ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  at org.apache.ignite.internal.IgniteKernal.startProcessor(IgniteKernal.java:1957) ~[ignite-core-2.9.0-p8.jar:2.9.0-p8]\n  ... 11 more\n  ```\nПроверьте, кем заняты порты из диапазона `portFrom` – `portTo`:\n\n```bash\nnetstat -anp | grep ПОРТ;\n```\n\nС большой вероятностью диапазон занят клиентским узлом. Если это так, отключите клиентский узел и перезапустите серверный, который не удавалось запустить. Когда серверный узел подключится, запустите клиентский."
  },
  {
    "question": "What are the potential reasons for the delay in launching the IGNITE-provider, and what steps can be taken to address these issues?",
    "answer": "Возможные проблемы:\n\n- Не запускается `ignite-provider 4.1.0` после обновления на WildFly (WF).\n- В `server.log` WildFly есть сообщение:\n  ```bash\n  Caused by: java.lang.ClassNotFoundException: org.apache.commons.lang.StringUtils from [Module \"deployment.ignite-provider-ear-4.1.0.ear\" from Service Module Loader] at org.jboss.modules.ModuleClassLoader.findClass(ModuleClassLoader.java:255) at org.jboss.modules.ConcurrentClassLoader.performLoadClassUnchecked(ConcurrentClassLoader.java:410) at org.jboss.modules.ConcurrentClassLoader.performLoadClass(ConcurrentClassLoader.java:398) at org.jboss.modules.ConcurrentClassLoader.loadClass(ConcurrentClassLoader.java:116) ... 37 common frames omitted\n  ```\nПерезапустите WildFly (WF). Данная проблема возникает, если после обновления не перезапустить WF."
  },
  {
    "question": "What are common strategies for diagnosing and resolving issues related to exceeding the maximum number of open file descriptors in an application?",
    "answer": "Возможные проблемы:\n\n- Узел не запускается.\n- Узел упал во время работы.\n- В log-файле узла есть сообщение вида:\n  ```bash\n  Caused by: java.io.IOException: Too many open files\n  at java.base/sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)\n  at java.base/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:533)\n  at java.base/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:285)\n  at org.apache.ignite.internal.util.nio.GridNioServer$GridNioAcceptWorker.processSelectedKeys(GridNioServer.java:2998)\n  at org.apache.ignite.internal.util.nio.GridNioServer$GridNioAcceptWorker.accept(GridNioServer.java:2928)\n  ... 3 more\n  ```\nДля диагностики проверьте лимиты количества открытых файлов. Посмотреть полную информацию об открытых файлах можно с помощью команды `lsof`. Если большинство открытых файлов относится к пользователю Ignite, убедитесь, что максимальное количество файлов рассчитано корректно.\n\nПроверка файловых дескрипторов в разрезе пользователей (`user` — имя пользователя):\n\n```bash\nsudo lsof -u user | wc -l\n```\n\nПроверка дескрипторов по всей файловой системе — файлы `/proc/sys/fs/file-nr` и `/proc/sys/fs/file-max`. В файле `/proc/sys/fs/file-nr` указаны 3 значения:\n\n1. Количество выделенных файловых дескрипторов.\n2. Количество выделенных, но не используемых файловых дескрипторов.\n3. Максимально возможное количество файловых дескрипторов (соответствует значению в файле `file-max`).\n\nЕсли второе значение всегда равно нулю — это не ошибка. Это означает, что все выделенные дескрипторы используются (ранее дескрипторы могли динамически назначаться, но не освобождаться после использования).\n\nУстановка лимитов в разрезе пользователей в файле `/etc/security/limits.conf` с помощью строки вида:\n\n```bash\n<domain> <type> <item> <value>\n```\n\nГде:\n\n- `domain` — пользователь;\n- `type` — тип ограничения (жесткое/мягкое);\n- `item` — объект ограничения для пользователя (максимальный размер файла, максимальное количество процессов, максимальное количество логинов и так далее);\n- `value` — значение ограничения.\n\nУстановка лимитов по всей файловой системе в файле `/etc/sysctl.conf` с помощью добавления строки вида (`number` — лимит):\n\n```bash\nfs.file-max=number\n```\nУвеличьте лимиты в случае необходимости и/или снизьте потребление.\n\n```bash\nquantity = (partition-number / server-number) + cache-groups\n```\n\nГде:\n\n- `quantity` — количество требуемых файловых дескрипторов;\n- `partition-number` — число партиций (файлов), которые распределены в соответствии с affinity-функцией во всем кластере DataGrid;\n- `server-number` — количество серверов;\n- `cache-groups` — количество партиций в реплицированных кеш-группах."
  },
  {
    "question": "What are the benefits of adding stripes to a swimming pool, and how can they be effectively implemented?",
    "answer": "При резком росте нагрузки запросы (кеш-операции и транзакции) могут накапливаться в очереди `striped pool executor`.\n\nЕсли очередь обслуживается неуспешно, график метрики `IgniteStripedThreadPoolExecutor` может выглядеть как кривая с резким ростом и продолжительным линейным падением или как прямая с долгим линейным ростом. Такие виды графиков свидетельствуют о проблемах с обработкой очереди запросов. Они связаны с тем, что очередь запросов накапливается слишком быстро и отдельные операции не успевают обрабатываться. Также о проблеме с накоплением очереди могут говорить сообщения о долгом выполнении запросов в log-файлах. Если очередь обслуживается успешно, на графике `IgniteStripedThreadPoolExecutor` будут наблюдаться узкие пики. Они демонстрируют резкие рост и спад.\nПодобные проблемы вызваны неравномерным распределением данных и/или неверным распределением ключей по партициям. Например, если ключи попали в одну партицию, запросы тоже будут попадать в одну и ту же партицию. Из-за этого остальные кеш-операции и транзакции будут находиться в режиме ожидания и формировать очередь на выполнение в одном потоке.\n\nДля решения проблемы найдите медленно выполняющиеся транзакции и передайте информацию о проблеме для оптимизации прикладным разработчикам."
  },
  {
    "question": "What are some effective strategies to identify and resolve high CPU utilization issues in server environments?",
    "answer": "Высокая утилизация CPU.\nДля решения проблемы высокой утилизации CPU с помощью Java-процесса нужно знать идентификатор PID (process identifier) проблемного процесса. Выполните следующие шаги:\n\n1. Получите потоки процесса по PID с помощью команды:\n   ```bash\n   ps aux -T | grep PID > psaux.txt\n   ```\n\n   В результате выполнения этой команды будет выведен список всех потоков процесса с утилизацией CPU по каждому из них. Чтобы понять, какой участок кода внутри JVM утилизировал CPU и в какой период времени, используйте атрибуты `SPID` и `%CPU`. Отсортируйте данные из столбца `%CPU` по убыванию.\n\n2. Соберите `thread dumps` с помощью команды:\n   ```bash\n   jstack -l PID > jstack.txt\n   ```\n\n   Для дальнейшей работы используйте атрибуты `SPID`, представленные в шестнадцатеричной системе счисления в поле `nid`.\n\n3. Сопоставьте атрибуты `%CPU` и `SPID`, которые получили на предыдущих двух шагах. Это сравнение поможет понять, какой участок кода внутри JVM утилизировал CPU и на какой период времени.\n\n:::{admonition} Пример\n:class: hint \n:collapsible:\n\nВ качестве примера используйется поток JVM с PID `2350369`.\n\n1. Запросите потоки процесса:\n   ```bash\n   ps aux -T | grep 2350369 > [psaux.txt]\n   ```\n\n2. Соберите `thread dumps`:\n   ```bash\n   jstack -l 2350369 > [jstack.txt]\n   ```\n\n   В примере самые нагруженные по CPU потоки — `738903` и `747596`. В шестнадцатеричной системе они соответствуют `b4657` и `b684C` соответственно.\n\n3. Найдите в `jstack` потоки с идентификаторами (`nid`) `b4657` и `b684c`:\n   ```bash\n   \"kafka-producer-network-thread | transport-lib-producer-[hostname]-[union-module]-[default]-[5ac8b7d4-b6c7-4506-bf4c-77a390e9ecad]\" #99 daemon prio=5 os_prio=0 tid=0x00007f8e098ea000 nid=0xb4657 runnable [0x00007f8e05964000]\n   java.lang.Thread.State: RUNNABLE\n\n   \"[union-module]-[com.sbt.core.commons.config_impl.PlatformPropertyLoaderImpl-pci-union-module-D-01.021.01------]-kafka-processor-thread-2\" #622 prio=5 os_prio=0 tid=0x00007f8a98043000 nid=0xb684c runnable [0x00007ef40abe9000]\n   java.lang.Thread.State: RUNNABLE\n   ```\n:::"
  },
  {
    "question": "What could be causing the unknown connection detected error leading to a drop in server node availability, as indicated by the log files?",
    "answer": "Возможные проблемы:\n\n- Серверные узлы аварийно завершают работу с трассировкой стека вида:\n   ```bash\n    YYYY-MM-DD 01:08:25.603 [ERROR][tcp-disco-srvr-[:47500]-#3-#57][] Critical system error detected. Will be handled accordingly to configured handler [hnd=StopNodeOrHaltFailureHandler [tryStop=false, timeout=0, super=AbstractFailureHandler [ignoredFailureTypes=UnmodifiableSet [SYSTEM_WORKER_BLOCKED, SYSTEM_CRITICAL_OPERATION_TIMEOUT]]], failureCtx=FailureContext [type=SYSTEM_WORKER_TERMINATION, err=java.net.SocketTimeoutException: Accept timed out]]\n   java.net.SocketTimeoutException: Accept timed out\n   at java.net.PlainSocketImpl.socketAccept(Native Method) ~[?:?]\n   at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:458) ~[?:?]\n   at java.net.ServerSocket.implAccept(ServerSocket.java:565) ~[?:?]\n   at java.net.ServerSocket.accept(ServerSocket.java:533) ~[?:?]\n   at org.apache.ignite.spi.discovery.tcp.ServerImpl$TcpServer.body(ServerImpl.java:6603) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n   at org.apache.ignite.internal.util.worker.GridWorker.run(GridWorker.java:120) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n   at org.apache.ignite.spi.discovery.tcp.ServerImpl$TcpServerThread.body(ServerImpl.java:6526) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n   at org.apache.ignite.spi.IgniteSpiThread.run(IgniteSpiThread.java:58) [ignite-core-2.9.0-p8.jar:2.9.0-p8]\n   YYYY-MM-DD 01:08:25.609 [ERROR][tcp-disco-srvr-[:47500]-#3-#57][] JVM will be halted immediately due to the failure: [failureCtx=FailureContext [type=SYSTEM_WORKER_TERMINATION, err=java.net.SocketTimeoutException: Accept timed out]]\n   ```\n\n- Перед падением появляются предупреждения вида:\n   ```bash\n   Unknown connection detected (is some other software connecting to this Ignite port?) [rmtAddr=/<rmtAddr>:52082, locAddr=/<localAddr>:47100]\n   ```\nИсточником попыток подключения в большинстве случаев может быть сканер безопасности.\n\nДополнительная обработка `SocketTimeoutException` добавлена в DataGrid в версиях 4.2110.4 и 4.2120.0. Чтобы решить проблему, перейдите на одну из указанных версий."
  },
  {
    "question": "What are the common causes of an \"Out of Memory Error\" due to being unable to create new native threads, and how can this issue be resolved in Java applications?",
    "answer": "Узел падает с ошибкой:\n\n```bash\nOutOfMemoryError: unable to create new native thread\n```\n`OutOfMemoryError` в данном случае говорит не о нехватке места в Java Heap или RAM, а о проблеме `OutOfResources`. У операционной системы недостаточно ресурсов для создания дополнительных потоков. Проблема редкая, так как обычно не требуется так много потоков.\n\nКоличество потоков в операционной системе ограничено и отличается для разных систем. В качестве решения проблемы рассмотрите возможность переписать прикладной код таким образом, чтобы Callable- и Runnable-потоки создавались с помощью `Executor`, то есть чтобы был контроль количества создаваемых потоков.\n\nЕсли JVM запускается через `systemd`, найдите `service status` и проверьте `maxTasks (tasks = threads) per process limit`."
  },
  {
    "question": "What are common causes of errors when using NULL cipher suites in network communications, and how can these issues be effectively resolved to ensure secure data transmission?",
    "answer": "Возможные проблемы:\n\n- Узел не присоединяется к топологии.\n- В log-файле есть сообщения вида:\n   ```bash\n   org.apache.ignite.IgniteException: Unable to establish secure connection. Was remote cluster configured with SSL? [rmtAddr=/xxx.x.x.x:47500, errMsg=\"No appropriate protocol (protocol is disabled or cipher suites are inappropriate)\"]\n   ```\nПо умолчанию при использовании плагина безопасности и SSL шифрование не используется (в целях снижения нагрузки на кластер). Для этого используются NULL Cipher Suites, которые отключены в версиях JDK 8u201 и новее. При попытке использования шифров в версии Java с отключенными NULL Cipher Suites можно наблюдать описанную выше ошибку.\n\nВарианты решения проблемы:\n\n- Исключите значения `NULL` из параметра `jdk.tls.disabledAlgorithms` файла `java.security`. Для этого в файле `$JAVA_HOME/jre/lib/security/java.security` (в версии 11 файл называется `jdk-11.0.2.jdk/Contents/Home/conf/security/java.security`) найдите строку:\n   ```bash\n   jdk.tls.disabledAlgorithms=SSLv3, RC4, DES, MD5withRSA, DH keySize < 1024, \\ \n   EC keySize < 224, 3DES_EDE_CBC, anon, NULL\n   ```\n\n   И замените ее на строку:\n\n   ```bash\n   jdk.tls.disabledAlgorithms=SSLv3, RC4, DES, MD5withRSA, DH keySize < 1024, \\ \n   EC keySize < 224, 3DES_EDE_CBC, anon\n   ```\n\n   Если не получается отредактировать файл `java.security`, скопируйте JDK в другую папку и измените `java.security` там. Измененный файл можно скопировать и использовать в среде разработки.\n\n- Создайте отдельный файл, например `disabledAlgorithms.properties`, и пропишите в нем:\n   ```bash\n   jdk.tls.disabledAlgorithms=SSLv3, RC4, DES, MD5withRSA, DH keySize < 1024, EC keySize < 224, 3DES_EDE_CBC, anon\n   ```\n\n- Запустите Java с опцией `java -Djava.security.properties=disabledAlgorithms.properties`."
  },
  {
    "question": "What specific errors occur when connecting using various `jdk.tls.disabledAlgorithms` configurations in Java, and how can these be resolved?",
    "answer": ""
  },
  {
    "question": "What are some common reasons for encountering incorrect signs or errors in Eastern Kentucky University (EKU) digital certificates, and how can they be resolved?",
    "answer": "Ошибки handshake SSL (`javax.net.ssl.SSLHandshakeException`): узел не может присоединиться к топологии.\n\nУ толстого клиента отсутствие `serverAuth` при наличии `clientAuth` приводит к тому, что клиенты входят в топологию и через некоторое время выходят из нее из-за ошибки взаимодействия по `TcpCommunication`.\nEKU (Extended Key Usage) должны содержать оба признака: `serverAuth` и `clientAuth`.\n\nВ плагине безопасности есть валидация параметров EKU. При неверных признаках узел будет завершать работу с одной из указанных ниже ошибок.\n\nПустой EKU:\n\n```bash\nYYYY-MM-DD 09:00:38.616 [ERROR][main][org.apache.ignite.internal.IgniteKernal] Got exception while starting (will rollback startup routine).\norg.apache.ignite.plugin.security.SecurityException: The ExtendedKeyUsage extension of the local node certificate is not set. Make sure ExtendedKeyUsage contains both 'serverAuth' and 'clientAuth'.\n```\n\nНе хватает какого-то признака в EKU:\n\n```bash\nYYYY-MM-DD 09:00:38.616 [ERROR][main][org.apache.ignite.internal.IgniteKernal] Got exception while starting (will rollback startup routine).\norg.apache.ignite.plugin.security.SecurityException: The ExtendedKeyUsage extension of the local node certificate is not valid. Make sure ExtendedKeyUsage contains both 'serverAuth' and 'clientAuth' [expEku=[x.x.x.x.x.x.x.x.x, \"x.x.x.x.x.x.x.x.x], certEku=[x.x.x.x.x.x.x.x.x]]\n```"
  },
  {
    "question": "**What could be causing the overflow of unacknowledged messages in the error queue, as indicated by the LOG files, leading to reduced system operations?**\n\nThis question aims to explore potential reasons behind the accumulation of unacknowledged messages, which may include issues such as network delays, resource constraints, misconfigurations, or software bugs that prevent message acknowledgment. Understanding these causes is essential for diagnosing and mitigating the impact on system performance.?",
    "answer": "При включенном SSL и/или плагине безопасности наблюдается снижение производительности и сообщения в log-файле вида:\n\n```bash\n[YYYY-MM-DDT15:16:46,231][WARN ][grid-nio-worker-tcp-comm-3-#26%TcpCommunicationSpi%][TcpCommunicationSpi] Unacknowledged messages queue size overflow, will attempt to reconnect [remoteAddr=/<ip-address:port>, queueLimit=4096]\n```\n\n```bash\n[YYYY-MM-DDT15:16:47,233][ERROR][grid-nio-worker-tcp-comm-3-#26%TcpCommunicationSpi%][TcpCommunicationSpi] Failed to process selector key ... at org.apache.ignite.internal.util.nio.ssl.GridNioSslHandler.encrypt(GridNioSslHandler.java:393) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.ssl.GridNioSslFilter.encrypt(GridNioSslFilter.java:337) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$DirectNioClientWorker.processWriteSsl(GridNioServer.java:1506) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$DirectNioClientWorker.processWrite(GridNioServer.java:1405) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$AbstractNioClientWorker.processSelectedKeysOptimized(GridNioServer.java:2529) [ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2281) [ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1910) [ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.worker.GridWorker.run(GridWorker.java:125) [ignite-core-2.15.0.jar:2.15.0] at java.lang.Thread.run(Thread.java:834) [?:?] [YYYY-MM-DDT15:16:47,234][WARN ][grid-nio-worker-tcp-comm-3-#26%TcpCommunicationSpi%][TcpCommunicationSpi] Client disconnected abruptly due to network connection loss or because the connection was left open on application shutdown ... at org.apache.ignite.internal.util.nio.ssl.GridNioSslHandler.encrypt(GridNioSslHandler.java:393) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.ssl.GridNioSslFilter.encrypt(GridNioSslFilter.java:337) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$DirectNioClientWorker.processWriteSsl(GridNioServer.java:1506) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$DirectNioClientWorker.processWrite(GridNioServer.java:1405) ~[ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$AbstractNioClientWorker.processSelectedKeysOptimized(GridNioServer.java:2529) [ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2281) [ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1910) [ignite-core-2.15.0.jar:2.15.0] at org.apache.ignite.internal.util.worker.GridWorker.run(GridWorker.java:125) [ignite-core-2.15.0.jar:2.15.0] at java.lang.Thread.run(Thread.java:834) [?:?]\n```\nВ потоке `grid-nio-worker-tcp-comm-3-#26%TcpCommunicationSpi%` сначала происходит превышение очереди неподтвержденных (unacknowledged) сообщений `TcpCommunication`, а затем принудительный разрыв соединения.\n\nПроблема возникает из-за роста очереди неподтвержденных сообщений `TcpCommunication` во время всплеска нагрузки, особенно при `putAll`. Оптимизируйте бизнес-нагрузку на кластер и/или выполните вертикальное и горизонтальное масштабирование кластера DataGrid.\n\nВ качестве обходного решения можно увеличить размер очереди (по умолчанию 4096). Для этого укажите параметр `TcpCommunicationSpi#unacknowledgedMessagesBufferSize`. Может потребоваться установить его больше в несколько раз, например `65535`. Выбранное значение нужно тщательно проверить во время нагрузочного тестирования."
  },
  {
    "question": "What are the common causes of data loss in persistence clusters, and how can these be effectively mitigated to ensure data integrity?",
    "answer": ""
  },
  {
    "question": "What are the potential causes for losing the main parties in a gaming environment following a server or cluster restart, and how can these issues be mitigated to ensure continuity?",
    "answer": "После перезапуска кластера в log-файлах узлов появляется сообщение:\n\n```bash\n[YYYY-MM-DD 15:30:43,662][WARN ]sys-#60%gridCommandHandlerTest0%[GridDhtPartitionTopologyImpl] Detected lost partitions [grp=default, parts=[3, 7, 13], topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0]]\n```\nСообщения говорят о потере основных партиций после перезапуска кластера, но данные все еще можно загрузить с диска.\n\nДля решения проблемы выполните действия:\n\n1. Запустите команду `control.sh --cache reset_lost_partitions cacheName1,cacheName2,...`.\n2. Запустите команду `control.sh --cache idle_verify`."
  },
  {
    "question": "What were the primary factors that led to the decision to implement the Partition of British India in 1947?",
    "answer": "Косвенные симптомы:\n\n- данные периодически не находятся по ключу, находятся не те данные или данные отсутствуют;\n- запрос уходит на один узел и выполняется корректно, но при запросе на другой ничего не возвращает.\nРасхождением партиций называется состояние, при котором содержимое резервной (backup) партиции отличается от содержимого соответствующей ей основной (primary) партиции. Такие расхождения можно зафиксировать по следующим атрибутам партиции:\n\n- `counter` — счетчик изменения партиций;\n- размер — количество записей;\n- хеш-сумма — результат обработки хеш-функцией данных, которые находятся в партиции.\n\nРасхождения в партициях могут возникать из-за дефектов при работе с транзакционными кешами или в результате аварийных остановок узлов.\n\nЕсли в партициях обнаружились расхождения, их нужно устранить, так как они могут привести к некорректному выполнению бизнес-логики.\n\nУ проблемы есть следующие симптомы:\n\n- значения метрик;\n- сообщения в log-файлах;\n- ошибки в отчете `idle_verify`.\n\nВ целях диагностики запустите утилиту `idle-verify` с помощью команды:\n\n```bash\n--cache idle_verify [--dump] [--skip-zeros] [--check-crc] [--exclude-caches cacheName1,...,cacheNameN] [--cache-filter DEFAULT|SYSTEM|PERSISTENT|NOT_PERSISTENT|USER|ALL] [cacheName1,...,cacheNameN]\n```\n\nГде:\n\n- `--dump` — перенаправление вывода результата работы в файл по пути `$IGNITE_HOME/work/`, формат названия файла `idle-dump-YYYY-MM-DDTHH24-MI-SS_sss.txt`.\n- `--skip-zeros` — пропуск партиций, в которых нет записей.\n- `--check-crc` — проверка CRC-страниц.\n- `--exclude-caches cacheName1,...,cacheNameN` — исключение кешей, по которым не нужно искать расхождения.\n- `--cache-filter DEFAULT|SYSTEM|PERSISTENT|NOT_PERSISTENT|USER|ALL` — тип кешей, по которым нужно искать расхождения:\n  - `DEFAULT` — пользовательские кеши или все кеши, которые явно указаны;\n  - `SYSTEM` — системные кеши;\n  - `PERSISTENT` — персистентные кеши;\n  - `NOT_PERSISTENT` — неперсистентные кеши;\n  - `USER` — пользовательские кеши (все кеши, кроме системных);\n  - `ALL` — все кеши независимо от типа и места хранения их данных.\n- `cacheName1,...,cacheNameN` — имена кешей, в которых нужно искать расхождения.\n\nУтилита может отработать с двумя результатами:\n\n- Отсутствие расхождений:\n   ```bash\n    The check procedure has finished, no conflicts have been found.\n   ```\n\n- Наличие расхождений:\n   ```bash\n   idle_verify task was executed with the following args: caches=[], excluded=[], cacheFilter=[DEFAULT] # Аргументы, с которыми запущен `idle_verify`.\n  idle_verify check has finished, found 3 conflict partitions: [counterConflicts=0, hashConflicts=148] # Количество конфликтов (в данном примере — три) с разбивкой по типам `counterConflicts` и `hashConflicts`.\n   Hash conflicts: # Все, что идет ниже, относится к расхождениям по хешу.\n\n   Conflict partition: PartitionKeyV2 [grpId=1095989593, grpName=card-stream-linker-service-cache-prom, partId=851] # Сообщение указывает на то, в какой партиции (`partId=851`) и какой кеш-группе (`grpId=1095989593`, `grpName=card-stream-linker-service-cache-prom`) выявлены расхождения.\n   Partition instances: [\n   PartitionHashRecordV2 [isPrimary=false, consistentId=93dce233-c0b2-4b3c-8562-28d621a69954, updateCntr=20600, partitionState=OWNING, size=17, partHash=318600276],\n   PartitionHashRecordV2 [isPrimary=true, consistentId=158db893-e309-407e-9cb5-32d14ade1748, updateCntr=20600, partitionState=OWNING, size=16, partHash=-119291370]]\n\n   Conflict partition: PartitionKeyV2 [grpId=1095989593, grpName=card-stream-linker-service-cache-prom, partId=286]\n   Partition instances: [\n   PartitionHashRecordV2 [isPrimary=false, consistentId=93dce233-c0b2-4b3c-8562-28d621a69954, updateCntr=20541, partitionState=OWNING, size=22, partHash=623413003],\n   PartitionHashRecordV2 [isPrimary=true, consistentId=158db893-e309-407e-9cb5-32d14ade1748, updateCntr=20541, partitionState=OWNING, size=21, partHash=845648234],\n   PartitionHashRecordV2 [isPrimary=false, consistentId=e6775c04-5c1d-416c-831c-ff5b37d23985, updateCntr=20541, partitionState=OWNING, size=21, partHash=845648234]]\n\n   Conflict partition: PartitionKeyV2 [grpId=1095989593, grpName=card-stream-linker-service-cache-prom, partId=285]\n   Partition instances: [\n   PartitionHashRecordV2 [isPrimary=false, consistentId=93dce233-c0b2-4b3c-8562-28d621a69954, updateCntr=20599, partitionState=OWNING, size=25, partHash=481674619],\n   PartitionHashRecordV2 [isPrimary=false, consistentId=158db893-e309-407e-9cb5-32d14ade1748, updateCntr=20599, partitionState=OWNING, size=24, partHash=1206168917],\n   PartitionHashRecordV2 [isPrimary=true, consistentId=e6775c04-5c1d-416c-831c-ff5b37d23985, updateCntr=20599, partitionState=OWNING, size=24, partHash=1206168917]]\n   ```\nВ качестве решения используйте механизм полуавтоматического выравнивания (Read repair). Он позволяет контролируемо устранить расхождения партиций с применением разнообразных стратегий (`LWW`, `PRIMARY`, `MAJORITY`, `REMOVE`, `REMOVE`, `CHECK_ONLY`). Подробнее о механизме написано в разделе [«Режим Read repair»](../../developer-guide/md/read_repair_mode.md) документа «Руководство прикладного разработчика»."
  },
  {
    "question": "How can resource allocation issues, specifically a lack of CPU resources, be effectively managed or mitigated when deploying applications on virtual machines?",
    "answer": "Возможные проблемы:\n\n- узлы выпадают с разными ошибками;\n- у метрики на `Steal Time` ненулевое значение.\nДля виртуальных машин выделено недостаточно CPU. Эскалируйте проблему на сопровождение виртуальной инфраструктуры."
  },
  {
    "question": "What are the potential causes of freezing or \"frosted\" behavior in virtual machines, and how can they be diagnosed and resolved?",
    "answer": "Возможные проблемы:\n\n- Узлы выпадают по тайм-ауту.\n- В GC-log присутствуют длительные GC-паузы. Содержимое GC-log выглядит так, как будто мусор некоторое время не собирался.\nПередайте проблему на анализ администраторам виртуальной инфраструктуры."
  },
  {
    "question": "What are some of the most common data storage challenges faced by modern organizations, and what strategies can be implemented to effectively address them?",
    "answer": ""
  },
  {
    "question": "What are the common causes and solutions for Java Heap Space Exhaustion in applications? \n\nThis question aims to delve into both the reasons behind heap space issues and the practical steps developers can take to address them. It covers understanding memory allocation, identifying memory leaks, optimizing garbage collection, and configuring JVM settings effectively to prevent or mitigate such problems.?",
    "answer": "Падение с ошибкой `OutOfMemoryError`.\n\n:::{admonition} Внимание\n:class: danger\n\nУтилизация heap, которая не приводит к `OutOfMemoryError`, не является проблемой. Триггеры по утилизации heap в мониторинге не приносят пользы.\n:::\nИсчерпание heap может быть спровоцировано неверным планированием емкости кластера, когда реальная нагрузка и использование ресурса выше запланированных. Например, причиной могут быть большие транзакции SQL с сортировками или группировками, а также `putAll` и `getAll`. Таким запросам нужно временно сохранять результат выборки.\n\nУтечку памяти нужно устранить. Если проблема не вызвана утечками памяти:\n\n- увеличьте объем heap на узлах — выставите опции `-xmx` и `-xms`;\n- увеличьте количество узлов.\n\n## Проблемы при работе CDC"
  },
  {
    "question": "What strategies can be implemented to diagnose and effectively eliminate failures in the operation and maintenance processes within Control, Data, Communication (CDC) systems?",
    "answer": "Нарушения в работе CDC могут вызывать следующие причины:\n\n- особенности использования CDC;\n- ошибки конфигурации серверных узлов и приложений CDC;\n- инфраструктурные ошибки и ошибки со стороны окружения;\n- смена public API при обновлении.\n\nКаждая из причин подробно описывается в разделах ниже.\nЕсть особенности в работе, которые стоит учитывать при настройке и эксплуатации, чтобы избежать ошибок в работе приложений CDC:\n\n- Нужно активировать кластеры-приемники, иначе появится ошибка:\n   ```text\n   Can not perform the operation because the cluster is inactive\n   ```\n\n- Нужно создать кеши в обоих кластерах, иначе появится ошибка:\n   ```text\n   Cache with id not found [cacheId=1231231]\n   ``` \n\n- В версиях DataGrid ниже 4.2130 до запуска CDC на всех кластерах нужно вставить какие-либо данные в реплицируемые кеши, чтобы зарегистрировать `binary metadata`. В противном случае появится ошибка:\n   ```text\n   BinaryObjectException: Cannot find metadata for object with compact footer\n   ``` \n\nОшибки возникают при применении изменений и приводят к остановке:\n\n- `ignite-cdc.sh` — в случае прямой репликации между кластерами DataGrid;\n- `kafka-to-ignite.sh` — в случае репликации DataGrid через Kafka/Corax.\nДля анализа проблем, которые связаны с CDC, выполните действия:\n\n1. Проверьте метрики и триггеры CDC в системе мониторинга. Убедитесь, что метрики по всем запущенным приложениям CDC увеличиваются на всех кластерах, если на них есть нагрузка.\n2. В случае репликации через Kafka/Corax проверьте метрики `log-end-offset` и `lag` в мониторинге Kafka/Corax.\n3. Проанализируйте log-файлы серверного узла (`ignite.log`) и приложений CDC (`ignite-cdc.log` и `kafka-ignite-streamer.log`) на предмет ошибок и предупреждений. Убедитесь, что данная проблема не относится к настройке DataGrid и плагина безопасности. Описание сообщений log-файлов при работе CDC есть в разделе [«Первичный анализ логов»](../../administration-guide/md/primary-analysis-of-logs.md) документа «Руководство по системному администрированию».\n4. Если на кластер-источник есть нагрузка и приложения CDC завершают работу в течение нескольких минут после запуска, возможно появление проблем с настройкой приложений.\n5. Если проблемы с CDC наблюдаются только при росте нагрузки на кластер-приемник, это может говорить о нехватке ресурсов для обработки событий репликации (медленная сеть или аппаратное обеспечение).\n6. Спонтанные ошибки, например тайм-ауты отправки, могут говорить о проблемах с сетью или аппаратным обеспечением.\nДля устранения данных ошибок проанализируйте log-файлы серверных узлов.\n\n##### Медленная ротация сегментов\n\n**Проблема:**\n\n- ступеньки в росте размеров кешей в системе мониторинга;\n- расхождение содержимого кешей и их размеров больше, чем ожидается (желтый график):\n![Graph](./resources/graph.png)\n\n**Решение:**\n\n1. В log-файлах серверных узлов проверьте частоту ротации WAL-сегментов:\n   ```bash\n   YYYY-MM-DD 05:35:35.768 [INFO ][grid-timeout-worker-#38][FileWriteAheadLogManager] Rollover segment [11324 to 11325], recordType=null\n   YYYY-MM-DD 06:54:46.798 [INFO ][grid-timeout-worker-#38][FileWriteAheadLogManager] Rollover segment [11325 to 11326], recordType=null\n   ```\n\n2. Если ротация очень редкая (минуты или часы), проверьте в конфигурации наличие параметра `walForceArchiveTimeout`:\n   ```bash\n    <bean class=\"org.apache.ignite.configuration.IgniteConfiguration\">\n   <property name=\"dataStorageConfiguration\">\n       <bean class=\"org.apache.ignite.configuration.DataStorageConfiguration\">\n       <property name=\"walForceArchiveTimeout\" value=\"10000\"/>\n   ... \n   ```\n\n##### Не включена запись журнала на серверном узле\n\n**Проблема**\n\nНе записывается журнал репликации, то есть в каталоге CDC не копятся сегменты и данные не реплицируются.\n\n**Решение**\n\nПроверьте, установлен ли параметр `cdcEnabled=true` для регионов данных (`DataRegion`), в которых находятся реплицируемые кеши (не путайте с режимом кешей `REPLICATED`). Если параметр не установлен, жесткие ссылки не будут создаваться и изменения не будут реплицироваться в кластер-приемник.\n\n##### Разные разделы WAL-архива и журнала репликации\n\nСегменты, которые расположены в каталоге журнала репликации, являются жесткими ссылками на сегменты WAL-архива. Linux не поддерживает создание жестких ссылок на файлы, которые расположены в другом разделе файловой системы. Для решения проблемы разместите WAL-архив и журнал CDC в одном разделе файловой системы.\n\nВ DataGrid версии 4.2130 и новее при запуске серверного узла появляется ошибка:\n\n```text\nPaths are not stored at the same device or partition. Creating hard links is not available.\n```\n\nВ DataGrid версии 4.2120 во время ротации WAL-сегмента на серверном узле возникает другая ошибка:\n\n```text\norg.apache.ignite.internal.processors.cache.persistence.StorageException: Failed to archive WAL segment\n...\nCaused by: java.nio.file.FileSystemException: /opt/ignite/data/.../xxxxxxxxxxxxxx.wal ->\n/opt/ignite/wal_archive/.../xxxxxxxxxxxxxx.wal: Invalid cross-device link \n```\n\n##### Некорректные параметры ConflictResolver\n\n:::{admonition} Примечание\n:class: note\n\nНастройка плагина `ConflictResolver` описана в разделе [«Разрешение конфликтов репликации при помощи CacheVersionConflictResolver»](../../administration-guide/md/administration-scenarios.md) документа «Руководство по системному администрированию».\n:::\n\nОшибки отображаются в серверных log-файлах, так как плагин `ConflictResolver` настраивается для серверных узлов.\n\n###### Не настроен ConflictResolver\n\nЕсли не настроен `ConflictResolver` или в нем не указаны требуемые кеши, при изменении данных в обоих кластерах будут дублироваться и зацикливаться сообщения репликации.\n\n**Симптомы:**\n\n- хаотично меняются значения в кеше и постоянно применяются события репликации;\n- нагрузки на кластеры нет, но в log-файлах `ignite-cdc.sh` и `kafka-to-ignite.sh` постоянно присутствуют сообщения `Event received`, `Applying put batch` или `Applying remove batch`;\n- CDC through Kafka: в топике событий растет `log-end-offset`, при определенной нагрузке может начать расти расхождение (`lag`);\n- в log-файлах серверного узла присутствуют сообщения о выполнении checkpoint и ротации WAL-сегментов (косвенный признак).\n\n**Решение:**\n\n1. Перезапустите все кластеры с корректной настройкой `ConflictResolver`. Если настроено поле `conflictResolvableField`, конфликты разрешатся автоматически.\n2. Проверьте и восстановите согласованность между кластерами (подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров)).\n\n###### Одинаковый clusterId\n\nОсновной симптом: с точки зрения решения конфликтов кластеры будут одинаковыми, поэтому произойдет безусловное применение событий репликации без сравнения значений `conflictResolvableField`. Две конкурентные вставки значения (`INSERT`) в разных кластерах применятся безусловно, это приведет к несогласованности.\n\n**Решение:**\n\n1. Задайте разные `clusterId` в настройках кластеров.\n2. Проверьте и восстановите согласованность между кластерами (подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров)).\n3. Устраните конфликты в прикладном коде или вручную.\n\n###### Не указано поле conflictResolveField\n\nЕсли не указать значение поля `CacheVersionConflictResolverPluginProvider#conflictResolveField`, конфликтные изменения (изменения одних и тех же записей в разных кластерах) не применятся, а в log-файлах серверных узлов появятся сообщения об ошибках вида:\n\n```bash\n[YYYY-MM-DDT18:03:12,756][ERROR][sys-stripe-13-#14][CacheVersionConflictResolverImpl] <cache_name> Conflict can't be resolved, update ignored [key=keyValue, fromCluster=1, toCluster=2]\n```\n\n**Решение:**\n\n1. Задайте поле `conflictResolveField` в настройках серверных узлов.\n2. Проверьте и восстановите согласованность между кластерами (подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров)).\n\n###### Отсутствует поле conflictResolveField в объектах\n\nЕсли в объектах не заданы значения полей, появится ошибка разрешения конфликта и записи в log-файле серверного узла вида:\n\n```bash\nYYYY-MM-DDT14:29:30,785 [ERROR][client-connector-#103%ignite-2029-server%][CacheVersionConflictResolverImpl] <CacheName> Error while resolving replication conflict. [field=modificationDate, key=org.examples.model.Key  [idHash=1992838831, hash=1745342858, keyId=2, stringId=ID2]]\njava.lang.NullPointerException: null\n    at org.apache.ignite.cdc.conflictresolve.CacheVersionConflictResolverImpl.isUseNew(CacheVersionConflictResolverImpl.java:128) ~[ignite-cdc-ext-14.1.0.jar:14.1.0]\n \n...\n \nYYYY-MM-DDT14:29:30,787 [ERROR][client-connector-#103%ignite-2029-server%][CacheVersionConflictResolverImpl] <CacheName> Conflict can't be resolved, update ignored [key=org.examples.model.Key  [idHash=1992838831, hash=1745342858, keyId=2, stringId=ID2], fromCluster=2, toCluster=1]\n```\n**Решение:**\n\n1. Исправьте код приложения или сервиса, который осуществляет вставки в DataGrid — укажите монотонно возрастающее значение `conflictResolveField` во вставляемых объектах.\n2. Проверьте и восстановите согласованность между кластерами (подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров)).\n\n###### Значение null для conflictResolveField\n\nЕсли в поле `conflictResolveField` задано значение `null`, появится ошибка разрешения конфликта и записи в log-файле серверного узла вида (трассировка стека может отличаться для разных типов полей):\n\n```bash\nYYYY-MM-DDT14:06:51,025 [ERROR][client-connector-#105%ignite-2029-server%][CacheVersionConflictResolverImpl] <CacheName> Error while resolving replication conflict. [field=modificationDate, key=org.examples.model.Key  [idHash=420148468, hash=321295221, keyId=1, stringId=ID1]]\njava.lang.NullPointerException: null\nat java.sql.Timestamp.compareTo(Timestamp.java:515) ~[?:1.8.0_322]\nat java.sql.Timestamp.compareTo(Timestamp.java:72) ~[?:1.8.0_322]\nat org.apache.ignite.cdc.conflictresolve.CacheVersionConflictResolverImpl.isUseNew(CacheVersionConflictResolverImpl.java:128) ~[ignite-cdc-ext-14.1.0.jar:14.1.0]\n...\n \nYYYY-MM-DDT14:06:51,030 [ERROR][client-connector-#105%ignite-2029-server%][CacheVersionConflictResolverImpl] <CacheName> Conflict can't be resolved, update ignored [key=org.examples.model.Key  [idHash=420148468, hash=321295221, keyId=1, stringId=ID1], fromCluster=2, toCluster=1]\n```\n\n**Решение:**\n\n1. Исправьте код приложения или сервиса, который осуществляет вставки в DataGrid — укажите монотонно возрастающее значение `conflictResolveField` во вставляемых объектах.\n2. Проверьте и восстановите согласованность между кластерами (подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров)).\n##### Клиенты DataGrid (тонкий, толстый)\n\nВсе ошибки можно разделить на два основных типа:\n\n- Ошибка плагина безопасности, аудита, параметров SSL или неверные имя пользователя и пароль.\n- Специфичные настройки DataGrid — неверный список адресов, неверные настройки клиентского узла Ignite и так далее. Например, перепутаны адреса кластеров или использованы сертификаты другого кластера.\n\nДанные ошибки не относятся напрямую к CDC и должны решаться таким же образом, как и проблемы настройки клиентских узлов и тонких клиентов. При разборе следует учитывать:\n\n- Для CDC Ignite2Ignite (прямая репликация между кластерам DataGrid) — клиент DataGrid запускается внутри приложения `ignite-cdc.sh` на каждом серверном узле кластера-источника (source cluster).\n- Для CDC Ignite through Kafka (репликация через Kafka/Corax) — клиент Ignite запускается внутри приложения `kafka-to-ignite.sh`. Для работы достаточно одного клиента на каждый кластер-приемник.\n\n##### Неверный путь к каталогу журнала CDC\n\nОшибка касается приложения `ignite-cdc.sh`. При настройке по умолчанию приложение запрашивает конфигурационный файл серверного узла. Возможные ошибки:\n\n- при использовании отдельного конфигурационного файла-дубликата серверной конфигурации с отличающимися путями к журналу CDC;\n- если путь к каталогу может меняться динамически, например зависеть от JVM-опций `CLUSTER_TYPE` и `CLUSTER_NAME`, когда эти опции отличаются для приложения CDC и серверного узла.\n\n##### Неверный список кешей\n\nПри указании неверного списка кешей возможны ситуации:\n\n- Реплицируются не все данные, если список неполный. К падению приложений это не приведет, но изменения в таком случае теряются. Можно решить проблему выгрузкой снепшота или данных через CDC (доступно в DataGrid версии 15.0.0 и новее). Подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров).\n- Приложение CDC завершает работу с ошибкой, так как кеш в кластере-приемнике не найден.\n\n##### Некорректное количество партиций Kafka\n\nЕсли количество партиций в конфигурации меньше, чем в топике Kafka:\n\n- `ignite-cdc.sh` — ошибок в работе и потери данных не будет.\n- `kafka-to-ignite` — если в настройках  `ignite-cdc.sh` указано верное количество партиций, `kafka-to-ignite.sh` будет вычитывать события только из части партиций. Это приведет к потере событий при очистке по тайм-ауту устаревших записей из топиков (из партиций Kafka/Corax, которые не вычитывались).\n\nЕсли количество партиций в конфигурации больше, чем в топике Kafka:\n\n- `ignite-cdc.sh` — завершит работу с ошибкой (по умолчанию через 60 секунд):\n   ```bash\n   YYYY-MM-DD 13:08:17.537 [ERROR][Thread-18][] Cdc error\n   java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException:\n   Topic TOPIC_NAME not present in metadata after 60000 ms.\n       at org.apache.ignite.cdc.kafka.IgniteToKafkaCdcStreamer.onEvents(IgniteToKafkaCdcStreamer.java:183) ~[ignite-cdc-ext-2.12.0-p7.jar:2.12.0-p7]\n       at org.apache.ignite.internal.cdc.WalRecordsConsumer.onRecords(WalRecordsConsumer.java:157) ~[ignite-core-2.12.0-p7.jar:2.12.0-p7]\n       at org.apache.ignite.internal.cdc.CdcMain.consumeSegment(CdcMain.java:472) ~[ignite-core-2.12.0-p7.jar:2.12.0-p7]\n   ```\n\n- `kafka-to-ignite.sh`  — ошибок в работе и потери данных не будет, но `KafkaConsumer` в приложении будет ожидать в течение `kafkaRequestTimeout` при запросе данных из несуществующих партиций. Это может привести к росту расхождений в Kafka/Corax по части партиций и росту разницы размеров и состава кешей между кластерами (в системе мониторинга Grafana).\n\n##### Слишком маленькое значение kafkaRequestTimeout (CDC through Kafka)\n\nПроблема — частое завершение работы `ignite-cdc.sh` и `kafka-to-ignite.sh` по тайм-ауту. Примеры ошибок находятся ниже в разделе [«Задержки при обмене сетевыми сообщениями»](#задержки-при-обмене-сетевыми-сообщениями).\n\nДля стабильной работы приложений `ignite-cdc.sh` и `kafka-to-ignite.sh` задавайте значение `kafkaRequestTimeout` в несколько раз больше `request.timeout.ms`. Это позволит клиенту Kafka/Corax совершить несколько повторных запросов.\n\nВ текущих версиях DataGrid значение по умолчанию для `kafkaRequestTimeout` (3 секунды) меньше значения по умолчанию для `request.timeout.ms` (30 секунд).\n\n## Нарушения со стороны окружения"
  },
  {
    "question": "What factors or criteria determine which CDC (Change Data Capture) processes are initiated, while others remain inactive?",
    "answer": ""
  },
  {
    "question": "What factors contribute to the constant discrepancy observed between different data clusters, and how can these discrepancies be effectively minimized or managed in clustering algorithms?",
    "answer": "Расхождение между кластерами является постоянным и не сокращается. Если убрать нагрузку с кластера-источника, выравнивания размеров кешей не происходит. При этом все процессы продолжают работать корректно, журнал репликации не копится. В случае использования репликации через Kafka/Corax также видно, что расхождение близко к нулю.\n\nТакое состояние говорит о том, что данные потеряны по одной из причин:\n\n- какое-то время была отключена запись CDC в кластере-источнике, при этом данные изменились;\n- была удалена часть WAL-сегментов в каталоге CDC;\n- данные потеряны в Kafka/Corax по истечении времени или переполнению места или удалены другим способом.\nПроверьте и восстановите согласованность между кластерами. Подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров)."
  },
  {
    "question": "What are the common causes of delays in network message transmission, and how can they be mitigated to ensure efficient data delivery?",
    "answer": "При ошибках и тайм-аутах обмена сообщениями между кластером-приемником и клиентом DataGrid последний ведет себя типичным для таких ситуаций образом. При первой ошибке применения событий в удаленный кластер приложение `ignite-cdc.sh` завершит работу. Проведите анализ ошибок подключения толстого или тонкого клиента к кластеру.\nОшибки при обращении в Kafka/Corax:\n\n- `ignite-cdc.sh`:\n  - Если обращение в Kafka/Corax происходит дольше, чем `kafkaRequestTimeout`, приложение завершает выполнение с ошибкой. Пример для тайм-аута 10 секунд:\n     ```bash\n     Caused by: java.util.concurrent.TimeoutException: Timeout after waiting for 10000 ms.\n         at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:78)\n         at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:30)\n         at org.apache.ignite.cdc.kafka.IgniteToKafkaCdcStreamer.sendOneBatch(IgniteToKafkaCdcStreamer.java:280)\n         ... 14 more \n     ```\n\n  - При прочих ошибках обращения к Kafka/Corax `ignite-cdc.sh` также завершит работу. Для диагностики ошибок обмена обратитесь к документации Kafka/Corax.\n\n- `kafka-to-ignite.sh`:\n  - При ошибках и тайм-аутах обмена сообщениями между кластером-приемником и клиентом DataGrid последний ведет себя типичным для таких ситуаций образом. При первой ошибке применения событий в удаленный кластер `kafka-to-ignite.sh` завершит работу.\n  - Если обращение в Kafka/Corax происходит дольше `kafkaRequestTimeout`, приложение `kafka-to-ignite.sh` может завершить выполнение с одной из ошибок. Пример для тайм-аута 10 секунд:\n     ```bash\n     [YYYY-MM-DDT17:14:11,512][ERROR][applier-thread-3][KafkaToIgniteCdcStreamerApplier] Applier error!\n     org.apache.kafka.common.errors.TimeoutException: Timeout of 10000ms expired before successfully committing the current consumed offsets\n\n     [YYYY-MM-DDT17:54:30,908][ERROR][applier-thread-1][KafkaToIgniteCdcStreamerApplier] Applier error!\n     org.apache.kafka.common.errors.TimeoutException: Failed to get offsets by times in 10013ms\n\n     [YYYY-MM-DDT17:58:01,155][ERROR][applier-thread-1][KafkaToIgniteCdcStreamerApplier] Applier error!\n     org.apache.kafka.common.errors.TimeoutException: Timeout of 10000ms expired before successfully committing the current consumed offsets\n\n     Failed to run app: Timeout expired while fetching topic metadata\n     class org.apache.ignite.IgniteException: Timeout expired while fetching topic metadata\n     at org.apache.ignite.cdc.kafka.AbstractKafkaToIgniteCdcStreamer.run(AbstractKafkaToIgniteCdcStreamer.java:127)\n     at org.apache.ignite.cdc.kafka.KafkaToIgniteCdcStreamer.run(KafkaToIgniteCdcStreamer.java:71)\n     at org.apache.ignite.cdc.kafka.KafkaToIgniteCommandLineStartup.main(KafkaToIgniteCommandLineStartup.java:68)\n     ```\n\n  - При прочих ошибках обращения к Kafka/Corax `kafka-to-ignite.sh` также завершит работу. Для анализа и устранения данных ошибок обратитесь к документации Kafka/Corax.\nЕсли все процессы CDC запущены, увеличивающаяся задержка возможна в ситуации, когда вставка в кластер-приемник не успевает за отправкой сообщений из кластера-источника:\n\n- Прямая репликация DataGrid в DataGrid: скорость генерации WAL выше, чем скорость применения в удаленный кластер — медленный удаленный кластер или сеть. В каталоге CDC копятся сегменты.\n- Репликация через Kafka/Corax:\n  - Низкопроизводительный кластер Kafka/Corax.\n  - Медленная запись в Kafka, быстрое чтение (`lag`) в Kafka/Corax нулевое. В каталоге CDC копятся WAL-сегменты.\n  - Медленный кластер-приемник — медленное чтение, `lag` в Kafka/Corax будет расти.\n\n##### Решение\n\nУстраните проблемы с производительностью, в первую очередь — с сетью, серверами DataGrid и Kafka/Corax."
  },
  {
    "question": "What are the best practices for managing and preventing lack of disk space issues related to WAL (Write-Ahead Logging) archives in database systems?",
    "answer": "WAL-сегменты копятся из-за того, что их не обрабатывает приложение `ignite-cdc.sh`. Длительное накопление приводит к падению серверных узлов из-за переполнения места в разделе с WAL-архивом.\nВ большинстве случаев проблема связана с тем, что не запущено приложение `ignite-cdc.sh`:\n\n1. Запустите процесс `ignite-cdc.sh`.\n2. Убедитесь, что он продолжает работу, а количество сегментов перестало увеличиваться.\n\n:::{admonition} Примечание\n:class: note\n\nВ версиях DataGrid до 14.1.2 при перестройке индексов в кластере без нагрузки происходит накопление сегментов, так как `ignite-cdc.sh` не удаляет обработанные сегменты. В данном случае может потребоваться очистка каталога CDC.\n\nЦелевое решение — обновление DataGrid. Работы по перестройке рекомендуется планировать после обновления.\n:::\n\nДополнительные рекомендации:\n\n- Следите за местом на диске.\n- Увеличьте раздел под WAL-архив.\n- При длительном отключении реплики можно отключать запись журнала (`cdcEnabled=false` или с помощью скрипта `control.sh`). Нужно учитывать, что это приведет к потере изменений и может потребовать восстановления согласованности (подробнее об этом написано ниже в разделе [«Восстановление согласованности кластеров»](#восстановление-согласованности-кластеров))."
  },
  {
    "question": "What are the potential impacts of losing Walrus (Wal) segments in genetic research, particularly regarding their role in genome stability and regulation?",
    "answer": "Учитывайте, что у клиентов и брокеров Kafka/Corax, которые запускаются в приложениях CDC, есть множество настроек, значительно влияющих на их поведение. Могут встречаться следующие ошибки:\n\n- Превышение допустимого размера сообщений для топика — `ignite-cdc.sh` завершит работу. Потребуется перенастройка топиков (брокеров).\n- Установка `auto.offset.reset=latest` в настройках `kafka-to-ignite.sh` приведет к тому, что при перезапуске чтение событий будет начинаться не с самого раннего события (`auto.offset.reset=earliest`), а с последнего. Это приведет к потере изменений, которые были записаны в топики между моментами остановки и последующего запуска. В таком случае потребуется восстановление согласованности — подробнее об этом написано в следующем разделе.\n- Установка `enable.auto.commit=true` может привести к ситуации, когда `kafka-to-ignite.sh` не смог применить изменения, а смещение успешно применилось. В таком случае изменения, которые не применились, будут утеряны. В `kafka-to-ignite.sh` используется ручное применение смещений только после успешного применения изменений, поэтому нужно установить `enable.auto.commit=false`.\n- Переполнение места в Kafka/Corax при большом потоке событий CDC. Решается повторным расчетом сайзинга Kafka."
  },
  {
    "question": "How can techniques like data reconciliation, machine learning algorithms, or periodic audits be effectively employed to restore and maintain the consistency of clusters in large-scale datasets?",
    "answer": ""
  }
]